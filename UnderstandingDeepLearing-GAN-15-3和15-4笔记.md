# C15 GAN 对抗生成网络
## 15.3 Progressive growing, minibatch discrimination, and truncation(渐进式增长、小批量判别和截断)PCGAN
上节说到，Wasserstein公式使GAN的训练更加稳定。但还要一些别的技巧来生成更高精度的数据(图像)，如渐进式增长(progressive growing),小批量判别(minibatch discrimination), 和截断(truncation)，这些都能提高了生成质量。
### 渐进式增长progressive growing
先来看一个简单的类比！^[https://www.cnblogs.com/mogebw/p/15971265.html]想象一下，俯瞰某处山区：山区有许多山谷，那里有漂亮的小溪和村庄，非常宜居。但是其间也会有许多山坡，它们崎岖不平，而且由于天气原因，通常不宜居住。我们用山谷和山坡类比损失函数，希望沿着山坡进入更好的山谷，以最小化损失。
我们可以把训练想象成将登山者放到这处山区的任意地方，让他顺着山坡往下的路进入山谷——这就是随机梯度下降所做的。但是，假设从一处非常复杂的山脉开始，登山者不知道该往哪个方向走。他周围的地势是崎岖不平的，以至于他很难弄清楚哪里是有宜居地的最宜人、最低的山谷。假如我们拉远画面并降低山脉的复杂度，使登山者对这一特定区域有一个高层次的了解。
随着登山者越来越接近山谷，我们再通过放大地形增加复杂性。这样不再只看到租糙像素化的构造，而是可以看到更精细的细节。这种方法的优势在于，当登山者沿着斜坡下山时，他可以很容易地进行一些小的优化以使旅行更加轻松，例如，他可以沿着一条干涸的小溪行走以更快地到达山谷。
**这就是渐进式増长(progressive growing)**：随着登山者的行进，提高地形的分辨率。
用专业术语来说，就是**训练过程正在从几个低分辨率的卷积层发展到多个高分辨率的层。**先训练早期的层，再引入更高分辨率的层——高分辨率层中的损失空间很难应对。
### 小批量判别/小批量标准偏差(minibatch discrimination)
人们通常希望能够生成真实数据集中所有人的脸，而不是只能生成某个女人的一张照片。为此， Karras等人创造了一种方法，使判別器可以辨别所获取的样本是否足够多样。这种方法本质上是**为判别器计算了一个额外的标量统计量。此统计量是生成器生成的或来自真实数据的小批量中所有像素的标准偏差。**
这是一个非常简单而优雅的解决方案：现在判别器需要学习的是，如果正在评估的批量中图像的标准偏差很低，则该图像很可能是伪造的——因为真实数据所具有的偏差较大。生成器别无选择，只能增加生成样本的偏差，才有机会欺骗判别器。
上述内容理解起来很直观，技术实现起来也非常简单，因为它只应用在判别器中。考虑到我们还想最小化可训练参数的数量，只添加一个额外的数字似乎就够了。该数字作为特征图附加到判别器上——维度或tf. shape列表中的最后一个数字。
### 截断(truncation)
在抽样过程中，只选择具有高概率（即接近平均值）的潜在变量z。**这减少了样品的变化，但提高了它们的质量。**如图15.10所示，(a)从左到右依次增加截断的区间，阈值分别为2,1.5,1,0.5,0.04，可以看出随着截断区间的增加，生成图像质量（FIDELITY）越来越高，但是多样性（VARIETY）越来越差。
![图15.10](/picture/udl-图15-10.png#pic_center)

## 15.4 Conditional generation(条件生成)
**GANs会产生真实的图像，但没有指定它们的属性**：我们不能选择头发的颜色、种族或面部的年龄，除非为每个特征组合训练单独的GANs。条件生成模型为我们提供了这种控制。
### 15.4.1 Conditional GAN
条件GAN将一个属性的向量c传递给生成器和判别器，故此时生成器和判别器写成${g[z,c,\theta]}$和${f[x,c,\phi]}$。
> 该生成器的目的是**将潜在变量z转换为具有正确属性c的数据样本x。**
> 而该判别器的目标是区分**具有目标属性的生成样本**或**具有真实属性的真实示例**（图15.13a)。

对于生成器，可以将属性c附加到潜在向量z上。
对于鉴别器，如果数据是一维的，则可以将其附加到输入器中。如果数据包含图像，则该属性可以线性转换为二维表示，并作为额外通道附加到鉴别器输入或其中间隐藏层中。

### 15.4.2 Auxiliary classifier GAN(ACGAN/辅助分类-GAN)
ACGAN通过要求鉴别器正确地预测该属性，从而简化了条件生成（图15.13b）。
ACGAN的原理GAN（CGAN）相似。对于CGAN和ACGAN，生成器输入均为潜在矢量及其标签，输出是属于输入类标签的伪造图像。对于CGAN，判别器的输入是图像（包含假的或真实的图像）及其标签， 输出是图像属于真实图像的概率。对于ACGAN，判别器的输入是一幅图像，而输出是该图像属于真实图像的概率以及其类别概率。^[https://blog.csdn.net/LOVEmy134611/article/details/109094647]

### 15.4.3  InfoGAN(可解释的生成对抗网络)
条件GAN和ACGAN都生成具有预定属性的样本。相比之下，**InfoGAN（图15.13c）试图自动识别重要的属性。**
生成器输入采用一个由随机噪声变量z和随机属性变量c组成的向量。
判别器既预测图像是真实的还是合成的，又估计属性变量。

![图15.13 Conditional generation](/picture/udl-图15-13.png#pic_center)


其他参考：
[历史最全GAN网络及其各种变体整理（附论文及代码实现）](https://zhuanlan.zhihu.com/p/34016536)